h2. A simple transaction system for the disk-based hash index.

The disk-based hash index is a standard disk-based hash index with pages.

A transaction system is necessary because sector writes seem not atomic in general. See the
discussion in "Crash-only software: More than meets the eye" on LWN for details (http://lwn.net/Articles/191059/).
Because a pages is shared by multiple keys a write by a single key might destroy the data integrity.
A deduplication system cannot rely on a backup system, well, because we are the backup system. We are
often the last line of defense.

The main idea of the transaction system is a forward transaction log. The goal is to
minimize write operations. The transaction system used only a single IO operation per transaction.

Before a modifying index operations writes to disk (Put, PutIfAbsent, Delete) the following data
is written to an transaction area:
 * The CRC of the original page buffer data
 * The CRC of the modified page buffer data
 * The modified page buffer data (Step 1)

Only when this data is written to the transaction file, the base write operation is done (Step 2). Nothing is
done during a commit or abort except that a lock is released. The transaction is not marked as done on disk to safe IO operations. We will later see that is is not necessary.

The transaction file has a limited number of places to which transaction data is written. The transaction
data is assigned to the places by modulo hashing on the bucket id. This means that no transactions on two buckets that map to the same transaction area index are possible. The likelihood of collisions can be reduces by using more transaction areas. But this allows to use a single static-size
file. During restore that also means that an open transaction in the transaction file is always the last update to a bucket as the bucket used the same transaction area all the time.

When the transaction system restarts, the transaction areas are checked:
 * If the transaction area is empty, nothing is done
 If the transaction area cannot be read, we assume that the Step 1 failed. This means by that the
original index data is clean and in its "before" state. If the data cannot be read because of a data
parsing failure and the data is equal to a known good state (transaction crc or original data crc) there
is a bug in dedupv1 that has nothing to do with the transaction or storage system.

 * If the index page is equal to the transaction crc, this means that the update operations was fine. Nothing is done here.
 * If the index page is equal to the original crc, this means that the system crashes before the write could take place. We are able to apply the modified page buffer data from the transaction data. However,
this is not strictly necessary for atomicity.
 * If the index page data doesn't match any crc, the write failed and corrupted the data. We are now able
to restore the page from the forward-logged data in Step 1.

The transaction system doesn't assume that the disk sector writes are atomic. The transaction system assumes
that it is reasonable unlikely that a garbaged (because of a partial write) page passes a CRC check.